{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxSqhyDMYKvB5fqlU7qH0n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install comet_ml -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KK6sIUdKVtr","executionInfo":{"status":"ok","timestamp":1669520717422,"user_tz":300,"elapsed":27673,"user":{"displayName":"An Ni Wu","userId":"11154020135232560694"}},"outputId":"cde4afb5-5117-4d79-bea3-8809043ebd2f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 441 kB 7.7 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 1.2 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 1.2 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 35.2 MB/s \n","\u001b[K     |████████████████████████████████| 498 kB 46.3 MB/s \n","\u001b[K     |████████████████████████████████| 130 kB 11.3 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 14.3 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 41.8 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 25.8 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 18.9 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 9.0 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 4.6 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 10.6 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 20.2 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 2.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 16.2 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 16.0 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 28.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 47.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 43.6 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 3.3 MB/s \n","\u001b[?25h  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nbuhXwuKbSw","executionInfo":{"status":"ok","timestamp":1669520739230,"user_tz":300,"elapsed":21835,"user":{"displayName":"An Ni Wu","userId":"11154020135232560694"}},"outputId":"1cd3e641-959b-4bd3-9fa6-89eeb88b1e20"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","RANDOM_SEED = 42\n","\n","# Load data\n","data_df = pd.read_csv('/content/drive/MyDrive/MMD6020_Final_Project/data/processed/chbmit_preprocessed_data.csv') \n","\n","# Separate X and y\n","y = data_df['Outcome']\n","X = data_df.drop(['Outcome'], axis=1)\n","\n","# Split into train and test\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, stratify=y, random_state=RANDOM_SEED)"],"metadata":{"id":"PuQyr3wvKn4v","executionInfo":{"status":"ok","timestamp":1669520825310,"user_tz":300,"elapsed":23641,"user":{"displayName":"An Ni Wu","userId":"11154020135232560694"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# AdaBoost"],"metadata":{"id":"oGOU92iYMmTK"}},{"cell_type":"code","source":["import os\n","\n","os.environ['COMET_API_KEY'] = \"gNf7yNnQQzusQKP74RiFgyQX8\""],"metadata":{"id":"4w8pb4zjMwsY","executionInfo":{"status":"ok","timestamp":1669521067721,"user_tz":300,"elapsed":4,"user":{"displayName":"An Ni Wu","userId":"11154020135232560694"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2JNg51rJJyj","outputId":"9491a852-e083-4b88-a704-b55125dc1be9"},"outputs":[{"output_type":"stream","name":"stderr","text":["COMET WARNING: Passing Experiment through Optimizer constructor is deprecated; pass them to Optimizer.get_experiments or Optimizer.next\n","COMET INFO: COMET_OPTIMIZER_ID=0ff1602f729f4331a051051397a2cb7b\n","COMET INFO: Using optimizer config: {'algorithm': 'bayes', 'configSpaceSize': 'infinite', 'endTime': None, 'id': '0ff1602f729f4331a051051397a2cb7b', 'lastUpdateTime': None, 'maxCombo': 0, 'name': 'Bayes Optimization', 'parameters': {'learning_rate': {'type': 'discrete', 'values': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}, 'n_estimators': {'max': 100, 'min': 20, 'scalingType': 'uniform', 'scaling_type': 'uniform', 'type': 'integer'}}, 'predictor': None, 'spec': {'gridSize': 10, 'maxCombo': 0, 'metric': 'loss', 'minSampleSize': 100, 'objective': 'minimize', 'retryAssignLimit': 0, 'retryLimit': 1000, 'seed': 42}, 'startTime': 58264035241, 'state': {'mode': None, 'seed': None, 'sequence': [], 'sequence_i': 0, 'sequence_pid': None, 'sequence_retry': 0, 'sequence_retry_count': 0}, 'status': 'running', 'suggestion_count': 0, 'trials': 3, 'version': '2.0.1'}\n","COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n","COMET INFO: Optimizer metrics is 'loss' but no logged values found. Experiment ignored in sweep.\n","COMET INFO: ---------------------------\n","COMET INFO: Comet.ml Experiment Summary\n","COMET INFO: ---------------------------\n","COMET INFO:   Data:\n","COMET INFO:     display_summary_level : 1\n","COMET INFO:     url                   : https://www.comet.com/mmd6020-projet-pratique/adaboost-pca/cb5104a9e6cb4b338665397ad306684c\n","COMET INFO:   Others:\n","COMET INFO:     notebook_url           : https://colab.research.google.com/notebook#fileId=1SNAaHWGftL6O2xHiFx_1l-Hxf20wVGLr\n","COMET INFO:     optimizer_count        : 1\n","COMET INFO:     optimizer_id           : 77d376e3dbd247bab3483976adc03b18\n","COMET INFO:     optimizer_metric       : loss\n","COMET INFO:     optimizer_metric_value : 1\n","COMET INFO:     optimizer_name         : Bayes Optimization\n","COMET INFO:     optimizer_objective    : minimum\n","COMET INFO:     optimizer_parameters   : {\"learning_rate\": 0.9, \"n_estimators\": 83}\n","COMET INFO:     optimizer_pid          : 0cbd9d21805853cafed0d99d153925771f5d2591\n","COMET INFO:     optimizer_process      : 76\n","COMET INFO:     optimizer_trial        : 1\n","COMET INFO:     optimizer_version      : 2.0.1\n","COMET INFO:   Parameters:\n","COMET INFO:     learning_rate : 0.9\n","COMET INFO:     n_estimators  : 83\n","COMET INFO:   Uploads:\n","COMET INFO:     environment details : 1\n","COMET INFO:     filename            : 1\n","COMET INFO:     installed packages  : 1\n","COMET INFO:     notebook            : 2\n","COMET INFO:     os packages         : 1\n","COMET INFO:     source_code         : 1\n","COMET INFO: ---------------------------\n","COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n","COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","COMET ERROR: Failed to calculate active processors count. Fall back to default CPU count 1\n","COMET INFO: Couldn't find a Git repository in '/content' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n","COMET INFO: Experiment is live on comet.com https://www.comet.com/mmd6020-projet-pratique/adaboost-pca/5f97ac50be7546a693f73ca768d8da0a\n","\n"]}],"source":["import numpy as np\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n","from sklearn.decomposition import PCA\n","\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.feature_selection import SelectKBest, chi2\n","\n","from imblearn.pipeline import Pipeline\n","\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import StratifiedKFold\n","\n","from comet_ml import Experiment\n","from comet_ml import Optimizer\n","from comet_ml import API\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","\n","def run_search(experiment, model, X, y, cv):\n","  # fit the model on the whole dataset\n","  results = cross_validate(\n","      model, X, y, cv=cv, \n","      scoring=[\n","          \"accuracy\",\n","          \"precision_macro\", \n","          \"recall_macro\", \n","          \"f1_macro\", \n","          \"roc_auc\",\n","      ], return_train_score=True)\n","\n","  for k in results.keys():\n","    scores = results[k]\n","    for idx, score in enumerate(scores):\n","      experiment.log_metrics({f\"cv_{k}\": score}, step=idx)\n","\n","    experiment.log_metrics({f\"cv_mean_{k}\": np.mean(scores)})\n","    experiment.log_metrics({f\"cv_std_{k}\": np.std(scores)})\n","\n","    experiment.log_parameter(\"random_state\", RANDOM_SEED)\n","    \n","def HyperParametersTuning(project_name, X_train, y_train):\n","\n","    # setting the spec for bayes algorithm\n","    spec = {\n","        \"objective\": \"minimize\",\n","        \"metric\": \"loss\",\n","        \"seed\": RANDOM_SEED\n","    }\n","\n","    # setting the parameters we are tuning\n","    model_params = {\n","        \"n_estimators\": {\n","            \"type\": \"integer\",\n","            \"scaling_type\": \"uniform\",\n","            \"min\": 20,\n","            \"max\": 100\n","        },\n","        \"learning_rate\": {\n","            \"type\": \"discrete\",\n","            \"values\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n","        },\n","    }\n","\n","\n","    # defining the configuration dictionary\n","    config_dict = {\n","        \"algorithm\": \"bayes\",\n","        \"spec\": spec, \n","        \"parameters\": model_params,\n","        \"name\": \"Bayes Optimization\", \n","        \"trials\": 3\n","    }\n","\n","    cv = StratifiedKFold(n_splits=5, random_state=RANDOM_SEED, shuffle=True) # use 5-fold stratified cv\n","\n","    # initializing the comet ml optimizer\n","    opt = Optimizer(\n","        api_key=os.environ.get('COMET_API_KEY'), # create an env var called 'COMET_API_KEY' containing the API key\n","        config=config_dict,\n","        project_name=project_name, # change name to model-selector\n","        workspace=\"mmd6020-projet-pratique\")\n","\n","   \n","    for experiment in opt.get_experiments():\n","\n","        n_estimators   = experiment.get_parameter(\"n_estimators\")\n","        learning_rate  = experiment.get_parameter(\"learning_rate\")\n","\n","        selector = PCA(n_components=12) # change selector for feature selection\n","\n","        clf_adaboost = AdaBoostClassifier(\n","            n_estimators=n_estimators,\n","            learning_rate=learning_rate,\n","            random_state=RANDOM_SEED)\n","\n","        # Pipeline\n","        steps = [('selector', selector), (\"clf_adaboost\", clf_adaboost)]\n","        pipeline = Pipeline(steps=steps)\n","\n","        run_search(experiment, pipeline, X_train, y_train, cv)\n","\n","        pipeline.fit(X_train, y_train)\n","        \n","        experiment.log_parameter(\"random_state\", RANDOM_SEED)\n","        experiment.end()\n","  \n","HyperParametersTuning(\"adaboost-pca\", X_train, y_train) "]},{"cell_type":"markdown","source":["# Logistic Regression"],"metadata":{"id":"4u9f2dPpPCs1"}},{"cell_type":"markdown","source":["# Random Forest"],"metadata":{"id":"cYsVHKs-O9tF"}},{"cell_type":"markdown","source":["# KNN"],"metadata":{"id":"Ee5-FRgPPF2a"}},{"cell_type":"markdown","source":["# XGBoost"],"metadata":{"id":"GAuCi47pPJuY"}}]}